{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook makes extensive use of examples and figures from [here](http://cs231n.github.io/convolutional-networks/), which is a great reference for further details.\n",
    "\n",
    "\n",
    "# GOALS\n",
    "\n",
    "* Understand how Image data is stored and used\n",
    "* Write a Multi-Class classification model\n",
    "* Be able to use convolutional layers\n",
    "* Build a network for Image Classification\n",
    "* Understand Over-fitting and some ways to deal with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: MNIST - Fashion\n",
    "\n",
    "For this example we'll use MNIST- Fashion, a collection of small 28x28 pixel images of various pieces of clothing. It is a common benchmark along with with the original MNIST which is a collection of hand written digits. We will load the data directly from keras.\n",
    "\n",
    "\n",
    "\n",
    "## The Task\n",
    "This is a multi-class classification problem, identify the type of object in the image\n",
    "\n",
    "|Label| Class  |\n",
    "|------ | ------|\n",
    "|    0|T-shirt/top|\n",
    "|    1|Trouser|\n",
    "|    2| Pullover|\n",
    "|    3| Dress|\n",
    "|    4| Coat|\n",
    "|    5| Sandal|\n",
    "|    6| Shirt|\n",
    "|    7| Sneaker|\n",
    "|    8| Bag|\n",
    "|    9| Ankle boot|\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll rely on tensorflow and the handy package Keras that comes with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='' #If you installed tensorflow to work with a GPU this will disable it\n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from random import random\n",
    "from sys import version\n",
    "print(\"Import complete\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(_xtrain, _ytrain), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "#We want to include a develop set so let's split the training set\n",
    "train_index=[]\n",
    "develop_index=[]\n",
    "for i in range(len(_xtrain)):\n",
    "    if random() <0.8:\n",
    "        train_index.append(i)\n",
    "    else:\n",
    "        develop_index.append(i)\n",
    "X_train=_xtrain[train_index]\n",
    "Y_train=_ytrain[train_index]\n",
    "\n",
    "X_develop=_xtrain[develop_index]\n",
    "Y_develop=_ytrain[develop_index]\n",
    "\n",
    "\n",
    "np.set_printoptions(linewidth=115)\n",
    "n_targets=np.max(Y_test)+1\n",
    "print('A Single Image:\\n',X_train[0])\n",
    "plt.imshow(X_train[0],cmap='gray')\n",
    "plt.show()\n",
    "print('Example Label:', Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note above that the labels are integers from 0-9\n",
    "* Also note the images are integers from 0-255 (uint8)\n",
    "\n",
    "We will deal with the labels first. Lets make some useful arrays and dictionaries to keep track of what each integer means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is useful for making plots it takes an integer\n",
    "lookup_dict={\n",
    "    0 :'T-shirt/top',\n",
    "    1 :'Trouser',\n",
    "    2 :'Pullover',\n",
    "    3 :'Dress',\n",
    "    4 :'Coat',\n",
    "    5 :'Sandal',\n",
    "    6 :'Shirt',\n",
    "    7 :'Sneaker',\n",
    "    8 :'Bag',\n",
    "    9 :'Ankle boot' \n",
    "}\n",
    "\n",
    "\n",
    "#Lets make a list in the order of the labels above so [T-Shirt,Trouser,...]\n",
    "labels=list(lookup_dict.values())\n",
    "\n",
    "#Check to make sure labels list is in the right order (not guaranteed in python < 3.6)\n",
    "if not all([v==lookup_dict[i] for i,v in enumerate(labels) ]):\n",
    "    print('This looks like an old version of python making labels the long way, you are using python version', version)\n",
    "    labels=['' for i in range(n_targets) ] #make a list with the right size\n",
    "    for key in lookup_dict:\n",
    "        labels[key]=lookup_dict[key] #Assign list to the vaules\n",
    "        \n",
    "#Always good to make simple checks that what you think is going to work actually is working\n",
    "#Here we check that our array of labels is in the same order as the dictionary we wrote above\n",
    "assert(all([v==lookup_dict[i] for i,v in enumerate(labels) ]))\n",
    "print(\"Array and dictionary are in same order\")    \n",
    "\n",
    "#Another Simple Check (Keras is well tested this will work, but it's good to get in the habit when using your own data)\n",
    "assert(len(X_train)==len(Y_train))\n",
    "print(\"X_train and Y_train are the same length\") \n",
    "assert(len(X_develop)==len(Y_develop))\n",
    "print(\"X_develop and Y_develop are the same length\")   \n",
    "assert(len(X_test)==len(Y_test))\n",
    "print(\"X_test and Y_test are the same length\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Classification\n",
    "\n",
    "**Reminder**\n",
    "   * Classification is problem where each of our examples (x) belongs to a class (y). Since Neural networks are universal function approximators, we can use $P(y|x)$\n",
    "\n",
    "**Like before to change our problem we need**\n",
    "* The correct activation on our last layer - **softmax**\n",
    "* The correct loss function - **categorical_crossentropy**\n",
    "\n",
    "We have more than two classes (0,1,2...) and we need to predict the probability of all of them. However, we have a constraint that all the probabilities must sum to one.\n",
    "\n",
    "**Our network**\n",
    " * Inputs are our images\n",
    " * Output is a Dense layer with dimension equal to the number of classes\n",
    "     * Each output represents $\\{P(y=0|x),(y=1|x),(y=2|x)\\ ...\\}$.\n",
    " * We require $\\sum_i P(y=i|x) = 1$.\n",
    "\n",
    "* To enforce this we use a different activation function: a **softmax**\n",
    "\n",
    "    * $\\sigma(x)_i= \\frac{e^{x_i}}{\\sum_i e^{x_i}}$\n",
    "    \n",
    "* Our loss function becomes\n",
    "\n",
    " $L=-\\frac{1}{N}\\sum_i \\sum_n y_{true,i,n}*ln(y_{pred,i,n})$\n",
    "\n",
    "* What this means\n",
    "    * $y_{true,i,n}$ is a vector with a 1 in the dimention that example belongs to and a zero everywhere else\n",
    "        *  i.e. Ankle boot = class 9 = (0,0,0,0,0,0,0,0,0,1)\n",
    "    * The sum in this loss term  $\\sum_n y_{true,i,n}*ln(y_{pred,i,n})$\n",
    "        * is zero except for the one value when n=class of $y_{true}$\n",
    "        * Then it's just $ln(y_{pred,i,n})$\n",
    "        * This is same as binary classfication: make -1*$ln(y_{pred,i,n})$ as small as possible\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input data set has labels stored as integers, but the labels we need for our loss function need to be  **one-hot** encoded\n",
    "\n",
    "**one-hot** - A vector of zeros except for one entry with a 1 that represents the class of an object\n",
    "   * i.e. Ankle boot = class 9 = (0,0,0,0,0,0,0,0,0,1)\n",
    "\n",
    "keras has a utility to convert integers like this easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_one_hot = tf.keras.utils.to_categorical(Y_train, 10)\n",
    "Y_develop_one_hot =  tf.keras.utils.to_categorical(Y_develop, 10)\n",
    "Y_test_one_hot =  tf.keras.utils.to_categorical(Y_test, 10)\n",
    "\n",
    "print('Example:',Y_train[0],'=',Y_train_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets handle the image data\n",
    "* Our Convolutional Neural Networks need a shape of Batch x Height x Width x Channels, for us (batch_size x 28 x 28 x 1)\n",
    "* In this case channels=1, but for a color image you'll have 3 RGB and sometimes 4 with a transparency channel RGBA \n",
    "* It's much easier for a neural network to handle data with range from 0-1, rather than 0-255, so we will scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f=plt.figure(figsize=(15,3))\n",
    "plt.imshow(np.squeeze(np.hstack(X_train[0:7])),cmap='gray') #hstack aranges the first 7 images into one long image\n",
    "\n",
    "#Reshape\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_develop = X_develop.reshape(X_develop.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "print(\"Datatype:\",X_train.dtype, \"\\nMax value:\", X_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the pixel values imported as an integer array that saturates at `255`.  Let's turn the data into floats $\\in [0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "if X_train.max()>1:  \n",
    "    X_train = X_train/255\n",
    "    X_test = X_test/255\n",
    "    X_develop = X_develop/255\n",
    "\n",
    "assert(np.max(X_train) <=1)\n",
    "assert(np.max(X_test) <=1)\n",
    "assert(np.max(X_develop) <=1)\n",
    "print(\"all sets scaled to float values between\", X_train.min(), \"and\", X_train.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Take Away\n",
    "\n",
    "* Image data is 3 dimensional (width,height,channel (i.e color) )\n",
    "    * It is often stored from 0-255 and should be normalized between 0-1\n",
    "* Class labels are given as integers and need to be converted to **one hot** vectors\n",
    "    \n",
    "* Multi-classification problems \n",
    "    * Use **softmax** as an output\n",
    "    * Use **Categorical Cross Entropy** as a loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Network for Image Classification\n",
    "\n",
    "* We can use everything we learned in Lesson 2 for Image classification\n",
    "* But we need one extra layer\n",
    "    * Dense Layers take 1-D data not 3-D data\n",
    "    * Convert the two by Flattening\n",
    "    * tf.keras.layers.Flatten()\n",
    "    \n",
    "All this does is reshape the input data\n",
    "\n",
    "$\\begin{pmatrix}a & b \\\\c & d\\end{pmatrix} \\rightarrow (a,b,c,d)$\n",
    "\n",
    "Let's try the network below \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer=tf.keras.layers.Input( shape=X_train.shape[1:] ) # Shape here does not include the batch size \n",
    "\n",
    "## Here is our magic layer to turn image data into something a dense layer can use\n",
    "flat_input=tf.keras.layers.Flatten()(input_layer )#Dense layers take a shape of ( batch x features)\n",
    "##\n",
    "hidden_layer1=tf.keras.layers.Dense(100)(flat_input)    \n",
    "hidden_layer_activation=tf.keras.layers.LeakyReLU()(hidden_layer1)\n",
    "hidden_layer2=tf.keras.layers.Dense(100)(hidden_layer1)\n",
    "hidden_layer_activation=tf.keras.layers.LeakyReLU()(hidden_layer2)\n",
    "output_layer=tf.keras.layers.Dense(n_targets,activation='softmax')(hidden_layer2)\n",
    "dense_model=tf.keras.models.Model(input_layer,output_layer)\n",
    "\n",
    "dense_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "dense_model.summary()\n",
    "\n",
    "history=dense_model.fit(X_train, Y_train_one_hot, \n",
    "          batch_size=32, epochs=10, verbose=1,\n",
    "         validation_data=(X_develop,Y_develop_one_hot)\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Curves\n",
    "\n",
    "The keras fit function returns a history object, that we've ignored until now, but it's a very important tool.\n",
    "It records the loss of the training and development datasets at each epoch, as well as metrics like accuracy.\n",
    "Let's plot the loss.\n",
    "\n",
    "**Most imporantly**\n",
    "* Is the development loss greater than the train loss?\n",
    "    * If so your model is overfit and will give worse performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll do this a lot so let's put it in a function\n",
    "def plot_history(history):     \n",
    "    plt.plot(history.history['loss'],label='Train')\n",
    "    plt.plot(history.history['val_loss'],label='Develop')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim((0,1.5*np.max(history.history['val_loss'])))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many techniques to deal with over-fitting and we'll talk more about them latter, but the easiest way is to just stop the training earlier. You can do this with\n",
    "\n",
    "\n",
    "```keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)```\n",
    "\n",
    "This is a callback, or a function that can be used to control the fitting process. It's called at the end of every epoch, or even the end of every batch. We can use these functions by adding them to the fit functions with\n",
    "\n",
    "\n",
    "```model.fit(...,\n",
    "  callbacks=[func1,func2])```\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    "history=dense_model.fit(X_train, Y_train_one_hot, \n",
    "          batch_size=32, epochs=10, verbose=1,\n",
    "         validation_data=(X_develop,Y_develop_one_hot),\n",
    "          callbacks=[es] \n",
    "                       )\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we picked up training where we left off the early stopping function quits training as soon as the develop loss stops going down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excerise 1\n",
    "\n",
    "With that let's practice writing our own Dense network image classifier\n",
    "We will a new dataset as an example cifar10\n",
    "\n",
    "\n",
    "labels=https://www.cs.toronto.edu/~kriz/cifar.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR data into train and test sets\n",
    "(_cfxtrain, _cfytrain), (cfX_test, cfY_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "#Split into Train and Develop\n",
    "\n",
    "train_index=[]\n",
    "develop_index=[]\n",
    "for i in range(len(_cfxtrain)):\n",
    "    if random() <0.8:\n",
    "        train_index.append(i)\n",
    "    else:\n",
    "        develop_index.append(i)\n",
    "cfX_train=_cfxtrain[train_index]\n",
    "cfY_train=_cfytrain[train_index]\n",
    "\n",
    "cfX_develop=_cfxtrain[develop_index]\n",
    "cfY_develop=_cfytrain[develop_index]\n",
    "\n",
    "f=plt.figure(figsize=(15,3))\n",
    "plt.imshow(np.hstack(cfX_train[0:7])) #hstack aranges the first 7 images into one long image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Scale your data to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Your code here normalize cfX_train/test/develop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set in [cfX_train,cfX_develop,cfX_test]:\n",
    "    assert np.max(data_set)==1., 'Max of your data set is '+str(np.max(data_set))+' not 1'\n",
    "    assert np.min(data_set)==0., 'Max of your data set is '+str(np.min(data_set))+' not 0'\n",
    "\n",
    "print('Great job! Your dataset is normalized correctly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Create One-Hot encoded labels\n",
    "Name them:\n",
    "* cfY_train_one_hot\n",
    "* cfY_develop_one_hot\n",
    "* cfY_test_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Your code here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'cfY_train_one_hot' in locals(),  'cfY_train_one_hot not found' \n",
    "assert 'cfY_develop_one_hot' in locals(),  'cfY_develop_one_hot not found' \n",
    "assert 'cfY_test_one_hot' in locals(),  'cfY_test_one_hot not found' \n",
    "\n",
    "assert (cfY_train_one_hot).shape[1]==10,  'cfY_train_one_hot not the correct size' \n",
    "assert (cfY_develop_one_hot).shape[1]==10,  'cfY_develop_one_hot not the correct size' \n",
    "assert (cfY_test_one_hot).shape[1]==10,  'cfY_test_one_hot not the correct size'\n",
    "print(\"One-Hot encoded labels created, correct size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Create a Dense Neural Network\n",
    "Write your own dense image classifier.\n",
    "\n",
    "Remeber you'll need: \n",
    "* an input layer\n",
    "* a flatten layer\n",
    "* some dense layers with activations\n",
    "* an output layer with a softmax activation\n",
    "\n",
    "Create and compile a model named **cifar_model**\n",
    "* Make sure the loss is catagorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"your code here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'cifar_model' in locals(), \"Could not find cifar_model\"\n",
    "assert cifar_model.input_shape ==(None,32,32,3), \"Check your input shape is correct\"\n",
    "assert cifar_model.output_shape[1] ==10, \"Check your output shape is correct\"\n",
    "assert cifar_model._is_compiled, \"Make sure to compile your model\"\n",
    "assert cifar_model.loss=='categorical_crossentropy', \"Check your loss to make sure it's correct\"\n",
    "assert (np.abs(np.sum(cifar_model.predict(cfX_train[0:10]),axis=1)-1) < 1e-5).all(), \"Outputs don't sum to 1 make sure you have the correct activation\"\n",
    "\n",
    "print('Fantastic Job! It looks like your model is ready to fit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fit your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history=cifar_model.fit(cfX_train, cfY_train_one_hot, \n",
    "          batch_size=32, epochs=10, verbose=1,\n",
    "         validation_data=(cfX_develop,cfY_develop_one_hot)\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Plot your loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"your code here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- BREAK -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above networks may or may not have worked particularly well, and while it's possible to get a network like this give you good accuracy all the time it requires some work, tunning, and has a bigger issue. Look at the summary of our first neural network\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Layer (type)           Output Shape              Param #  \n",
    "=================================================================\n",
    "flatten (Flatten)      (None, 784)               0       \n",
    "_________________________________________________________________\n",
    "\n",
    "dense(Dense)           (None, 100)              78500      \n",
    "_________________________________________________________________\n",
    " ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our first layer has 28 * 28 * 1 * 100 = 78,500 weights, which is fine for this size image.  What about using even a low resolution image of 300 * 300 * 3 * 100= 27 Million parameters for one layer. This is still possible with modern GPUs, but does not general yield good results. We need a solution that does not scale with with the number of pixels!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 300x300x3 pixel Image\n",
    "<img src=\"../assets/small_img.jpg\" style=\"width:100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks also don't fully utilize what we know about images for example we know that a rock above would still be a rock if we've moved it several pixels to the right of left, but a Dense network would have to learn a whole new set of weights to find a rock a every location in an image. This isn't very efficient. \n",
    "\n",
    "* Dense Neural networks treat each pixel as a separate features\n",
    "    * In image analysis we are often looking for a group of pixels somewhere in an image\n",
    "        *i.e. Cells, Tumors, or Ankle boots\n",
    "* We can use a new Layer that looks at a small patch of the image to create an interesting feature\n",
    "    * This is a **Convolutional Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/cnn.jpeg\" style=\"width:100\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs preserve the spatial (2-D) information of the input images, add a depth to their layers, and reduce the number of connections (and therefore weights).\n",
    "\n",
    "The layers used to build CNN *architectures* fall into three categories:\n",
    " 1. Convolutional Layer\n",
    " 1. Pooling Layer\n",
    " 1. Fully-Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/cnn/depthcol.jpeg\" style=\"width=100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layers consist of a set of filters that apply over a small spatial area, but the full depth of the input.  The example above shows on the left a [32x32x3] input volume (width 32, height 32 image with RGB color channels).  The volume on the right is an example of a convolutional layer, with a particular **depth column** highlighted which takes as input *only* the highlighted region of the input volume.  The spatial extent of the area covered by a depth column is referred to as the **receptive field**.\n",
    "\n",
    "The dimensions of the *output volume* are decided by 3 hyperparameters: **depth**, **stride**, and **zero-padding**.  We can compute the size of the output volume based on the volume size $W$, the receptive field size of the convolution layer $F$, their applied stride $S$, and the amount of zero padding used $P$.\n",
    "\n",
    "Based on these parameters, the number of pixels in the output of a convolutional layer is $(W−F+2P)/S+1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/cnn/stride.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a 1-D example with inputs on the bottom in blue ($W=5$) with a padding of 1 ($P=1$), and two different examples of a convolutional filter in red, both with receptive field $F=3$.\n",
    "\n",
    "*Left*: This is a convolutional layer with stride $S = 2$, meaning we expect ($5 - 3 + 2)/2+1 = 5$ neurons (i.e., outputs).\n",
    "\n",
    "*Right*: Layer with stride $S = 2$, meaning an output of size $(5 - 3 + 2)/2+1 = 3$.\n",
    "\n",
    "Note how on the left the zero padding allowed us to have the same number of outputs as inputs.  This is a common use of zero-padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can dramatically reduce the number of parameters involved in a convolutional layer by making the assumption that if one feature is useful to compute at some spatial position (x,y), then it should also be useful to compute at a different position (x2,y2).\n",
    "\n",
    "In other words, denoting a single 2-dimensional slice of depth as a depth slice (e.g. a volume of size [7x7x3] has 3 depth slices, each of size [7x7]), we are going to constrain the pixels in each depth slice to use the same weights and bias. All $7\\times7$ pixels in each depth slice will now be using the same parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://harishnarayanan.org/images/writing/artistic-style-transfer/conv-layer.gif\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Lets look at the how the first output pixel is calculated\n",
    "\n",
    "|X[0:3,0:3,0]|W0[:,:,0]| \n",
    "|------ | ------|\n",
    "|0,0,0  |-1,0,1|\n",
    "|0,0,0  |0,0,1 |\n",
    "|0,1,0  |1,-1,1|\n",
    "|first channel = | -1|\n",
    "+\n",
    "|X[0:3,0:3,1]|W0[:,:,1]|\n",
    "|0,0,0  |-1,0,1|\n",
    "|0,2,1  |1,-1,1|\n",
    "|0,2,1  |0,1,0|\n",
    "|second channel = |1|\n",
    "+\n",
    "|X[0:3,0:3,2]|W0[:,:,2]|\n",
    "|0,0,0  |-1,1,1|\n",
    "|0,2,1  |1,1,0 |\n",
    "|0,1,0  |0,-1,0|\n",
    "|third channel= | 1|\n",
    "|bias = |1 |\n",
    "|Sum Total| 2 = O[0,0,0]|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling layers act to reduce the dimension of the propagated volume, reducing the number of weights going forward, reducing cost and reducing the chances of over-fitting.  It operates independently on each depth slice.  A common operation is to take the MAX over a region.\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/pool.jpeg\" style=\"width:300\">\n",
    "\n",
    "For example,\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/maxpool.jpeg\" style=\"width:500\">\n",
    "\n",
    "**NOTE**: These are being used less and less these days, in favor of other methods such as strided convolutions seen above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to the MNIST hand-written digits data set.  First we'll download some external images that will be useful for visualizations later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In keras we can do everything we discussed above by adding an extra layer\n",
    "\n",
    "\n",
    "* tf.keras.layers.Convolution2D(Number of Filters, (Filter Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our example model\n",
    "* One convolutional layer\n",
    "    * 10 Filters\n",
    "    * Each filter (28x28)\n",
    "* Maxpooling\n",
    "* Softmax layer\n",
    "\n",
    "Each filter is the size of our entire image, and goes directly into predictions\n",
    "\n",
    "**Note**: This is not a standard algorithm design, but does show\n",
    "* How a filter works\n",
    "* How we can view intermediate layers\n",
    "* Will build some intuition when using CNNs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_input=tf.keras.layers.Input( shape=X_train.shape[1:] ) # Shape here does not including the batch size \n",
    "cnn_layer1=tf.keras.layers.Convolution2D(10, (28,28),padding='same')(cnn_input) \n",
    "cnn_activation=tf.keras.layers.LeakyReLU()(cnn_layer1) \n",
    "max_pooling=tf.keras.layers.MaxPooling2D(28)(cnn_activation) \n",
    "flat=tf.keras.layers.Flatten()(max_pooling) \n",
    "output=tf.keras.layers.Activation('softmax')(flat)\n",
    "model=tf.keras.models.Model([cnn_input],[output])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history=model.fit(X_train, Y_train_one_hot, \n",
    "          batch_size=32, epochs=5, verbose=1,\n",
    "         validation_data=(X_develop,Y_develop_one_hot)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use something called a keras function to explore our model layer by layer\n",
    "* A keras function is a lot like a keras Model, but doesn't have any code to do things like fitting\n",
    "\n",
    "tf.keras.backend.function([...Inputs...],[...outputs...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to get the output of all layers (except the first which is the input layer)\n",
    "image_index=8\n",
    "\n",
    "\n",
    "layers=tf.keras.backend.function([model.input],[ l.output for l in model.layers[1:]])\n",
    "\n",
    "\n",
    "layers_output=layers([X_train[image_index:image_index+1]]) \n",
    " \n",
    "print(\"Input\")\n",
    "plt.imshow(np.squeeze(X_train[image_index]),cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"CNN layer filters\")\n",
    "\n",
    "filters=np.squeeze(model.layers[1].get_weights()[0])\n",
    "print(filters.shape)\n",
    "filter_stack=np.hstack([filters[:,:,i] for i in range(10)   ])\n",
    "f=plt.figure(figsize=(20,2))\n",
    "\n",
    "plt.imshow(filter_stack,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"CNN Layer Output\")\n",
    "\n",
    "\n",
    "print(layers_output[0].shape)\n",
    "cnn_out=np.squeeze(layers_output[0])\n",
    "\n",
    "cnn_stack=np.hstack([cnn_out[:,:,i] for i in range(10)   ])\n",
    "f=plt.figure(figsize=(20,2))\n",
    "plt.imshow(cnn_stack,cmap='gray')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "print(\"Activation\")\n",
    "act_out=np.squeeze(layers_output[1])\n",
    "\n",
    "act_stack=np.hstack([act_out[:,:,i] for i in range(10)   ])\n",
    "f=plt.figure(figsize=(20,2))\n",
    "plt.imshow(act_stack,cmap='gray')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "print(\"Pooling\")\n",
    "pool_out=np.squeeze(layers_output[2])\n",
    "print(pool_out)\n",
    "\n",
    "#layer 3 is just a Flatten\n",
    "\n",
    "print(\"Softmax\")\n",
    "p_out=np.squeeze(layers_output[4])\n",
    "print(p_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a better model\n",
    "\n",
    "1. The simplest thing to improve the above model is to add a Dense layer at the end\n",
    "    * The Convolutional layer will learn the features that go into the dense network\n",
    "**Try the above model with a Dense layer at the end **\n",
    "* Can you still make sense of the filter's?\n",
    "\n",
    "2. Use smaller filters\n",
    "\n",
    "The above model (without the Dense layer) essentially learned a template for each class, this worked ok, but doesn't work in general or if you have a huge number of classes. Instead of using a few big filters, we can use a number of small filters, and stack them into deep networks.\n",
    "\n",
    "* This model will use several small filters\n",
    "* The layers will be stacked\n",
    "    * Earlier layer's will do simple things like edge detection\n",
    "    * Later layers will take those edges as features which lets them learn more complex objects\n",
    "    \n",
    "3. Replace MaxPooling with Strided Convolutions\n",
    "    * Let's the model learn the best way to downsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_input=tf.keras.layers.Input( shape=X_train.shape[1:] ) # Shape here does not including the batch size \n",
    "\n",
    "cnn_layer1=tf.keras.layers.Convolution2D(64, (4,4),strides=2,padding='same')(cnn_input) \n",
    "cnn_activation=tf.keras.layers.LeakyReLU()(cnn_layer1) \n",
    "\n",
    "cnn_layer2=tf.keras.layers.Convolution2D(64, (4,4),strides=2,padding='same')(cnn_activation) \n",
    "cnn_activation=tf.keras.layers.LeakyReLU()(cnn_layer2) \n",
    "\n",
    "cnn_layer3=tf.keras.layers.Convolution2D(64, (4,4),strides=2,padding='same')(cnn_activation) \n",
    "cnn_activation=tf.keras.layers.LeakyReLU()(cnn_layer3) \n",
    "\n",
    "flat=tf.keras.layers.Flatten()(cnn_activation) \n",
    "\n",
    "dense_layer=tf.keras.layers.Dense(10)(flat) \n",
    "output=tf.keras.layers.Activation('softmax')(dense_layer)\n",
    "\n",
    "model=tf.keras.models.Model([cnn_input],[output])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history=model.fit(X_train, Y_train_one_hot, \n",
    "          batch_size=32, epochs=5, verbose=1,\n",
    "         validation_data=(X_develop,Y_develop_one_hot)\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Intermediate Layers\n",
    "\n",
    "This network works well, but when we try to visualize the 64 filters, and 64 \"activation maps\" the output becomes a lot harder to interpret . You may have heard this called the 'black box' problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#A function to get the output of all layers (except the first which is the input layer)\n",
    "image_index=8\n",
    "\n",
    "\n",
    "layers=tf.keras.backend.function([model.input],[ l.output for l in model.layers[1:]])\n",
    "\n",
    "\n",
    "layers_output=layers([X_train[image_index:image_index+1]]) \n",
    " \n",
    "print(\"Input\")\n",
    "plt.imshow(np.squeeze(X_train[image_index]),cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"CNN layer filters\")\n",
    "\n",
    "filters=np.squeeze(model.layers[1].get_weights()[0])\n",
    "print(filters.shape)\n",
    "filter_stack=np.vstack([np.hstack([filters[:,:,i+n*8] for i in range(8)   ]) for n in range(8)])\n",
    "f=plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.imshow(filter_stack,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for layer_index in range(3):\n",
    "\n",
    "    print(\"CNN Layer Output\")\n",
    "\n",
    "\n",
    "    print(layers_output[layer_index*2].shape)\n",
    "    cnn_out=np.squeeze(layers_output[layer_index*2])\n",
    "\n",
    "    cnn_stack= np.vstack([  np.hstack([cnn_out[:,:,i+8*n] for i in range(8)   ]) for n in range(8)])\n",
    "\n",
    "    f=plt.figure(figsize=(20,20))\n",
    "    plt.imshow(cnn_stack,cmap='gray')\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "    print(\"Activation\")\n",
    "    act_out=np.squeeze(layers_output[1+layer_index*2])\n",
    "\n",
    "    act_stack= np.vstack([  np.hstack([act_out[:,:,i+8*n] for i in range(8)   ]) for n in range(8)])\n",
    "\n",
    "   \n",
    "    f=plt.figure(figsize=(20,20))\n",
    "    plt.imshow(act_stack,cmap='gray')\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "#    print(\"Pooling\")\n",
    "#    pool_out=np.squeeze(layers_output[2])\n",
    "#    print(pool_out)\n",
    "\n",
    "#layer 3 is just a Flatten\n",
    "\n",
    "print(\"Softmax\")\n",
    "p_out=np.squeeze(layers_output[-1])\n",
    "print(p_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Overfitting\n",
    "\n",
    "Overfitting generally refers to a trend for ML models to find and exploit statistical fluctuations in your training data that don't accurately reflect the system you are trying to learn. You can think of this a 'memorizing' without any real understanding. A good way of testing whether this is happening or not is to compare the training loss to the loss calculated on a new set of data (with it's own different statistical fluctuations)\n",
    "\n",
    "* Overfitting is combated \n",
    "    * with Dropout (more on that later)\n",
    "    * with less training or Early stopping (see https://keras.io/callbacks/#earlystopping)\n",
    "\n",
    "Keras's fit function returns a history object that shows the loss of the training and testing set we can check it for signs of overfitting.\n",
    "\n",
    "* You expect for the training and testing loss to go down \n",
    "* If the model starts overfitting \n",
    "    * you'll see the testing loss stop decreasing and even go up \n",
    "    * Training loss will continue to go down\n",
    "* An important detail: Keras has two learning_phases\n",
    "    * Training: The Model is training and dropout is on reducing available information\n",
    "    * Testing: This is the setting when using the model for real, dropout is disabled\n",
    "    * The Training loss is calculated with the training phase (dropout on)\n",
    "    * The Testing loss is calculated with the testing phase (dropout off)\n",
    "        * You will often see the Training loss is greater than the testing loss, this is okay if you're using dropout\n",
    "        * It might not be okay if you're using your own data without dropout\n",
    "            * Could be a sign the testing data is distributed differently than the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Testing Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any sign of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "Lets look at how the model makes predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)\n",
    "for i,p in enumerate(pred[0]):\n",
    "    print(lookup_dict[i],round(p*100,2),'%')\n",
    "\n",
    "best_guess=np.argmax(pred[0])\n",
    "print('best guess:',lookup_dict[best_guess])\n",
    "plt.imshow(np.squeeze(X_test[0]),cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('Truth Class:',Y_test[0],lookup_dict[Y_test[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice Above that the while the most likely guess is correct (Ankle boot when I ran it 23.2 percent), the model still isn't that confident in it's result. So while the accuracy is good there is still some improvements that might give you better confidences, and lower losses.  \n",
    "\n",
    "## Other Checks\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "A confusion matrix is a 2-D histogram with the dimensions being the true class, and the predicted class.\n",
    "The diagonal bins in this histogram are correct prediction true_class==predicted_class, otherwise it is an\n",
    "incorrect prediction. Run the cell below and see if you can guess which class is hardest to identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check(model,x,y):\n",
    "    pred=model.predict(x)\n",
    "    print(\"making\", pred.shape[0], \"predictions for\", pred.shape[1], \"classes\") \n",
    "    best_guess=np.argmax(pred,axis=1)\n",
    "\n",
    "    confusion_matrix=np.zeros((n_targets,n_targets))\n",
    "    for truth,guess in zip(y,best_guess):\n",
    "        confusion_matrix[truth,guess]+=1\n",
    "\n",
    "    plt.imshow(confusion_matrix)\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.xticks(range(0,10),labels,rotation=90)\n",
    "    plt.yticks(range(0,10),labels)\n",
    "\n",
    "    plt.show()\n",
    "    print('Number of Incorrect Guesses:',np.sum(best_guess!=y))\n",
    "\n",
    "    \n",
    "    prediction_for_true_value=[p[i] for p,i in zip(pred,y)  ]\n",
    "\n",
    "    bins=plt.hist(prediction_for_true_value,bins=30,range=(0,1))\n",
    "    plt.title('Output for Correct Classes')\n",
    "    \n",
    "    worst=np.argsort(prediction_for_true_value)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    plt.show()\n",
    "\n",
    "    for index in worst[0:5]:\n",
    "        print(\"Guess:\", lookup_dict[best_guess[index]], \"/Truth:\",lookup_dict[y[index]])\n",
    "        plt.imshow(np.squeeze(x[index]),cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "check(model,X_test,Y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips and Tricks\n",
    "\n",
    "* Dropout\n",
    "* Data Augmentation\n",
    "* Which Activation functions to use inside your network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Put of this together into some helpful functions\n",
    "def build_model(dropout_rate=0.25,nfilters=32,use_leakyRelu=False,activation='relu'):\n",
    "    if use_leakyRelu:\n",
    "        activation='linear'\n",
    "    \n",
    "    cnn_input=tf.keras.layers.Input( shape=X_train.shape[1:] ) # Shape here does not include the batch size \n",
    "    cnn_layer1=tf.keras.layers.Convolution2D(nfilters, (3, 3), activation=activation)(cnn_input) #Notice here calling the layer with cnn_input as an argument connects the input layer to this layer \n",
    "    if use_leakyRelu:cnn_layer1=tf.keras.layers.LeakyReLU()(cnn_layer1)\n",
    "    cnn_layer2=tf.keras.layers.Convolution2D(nfilters, (3, 3), activation=activation)(cnn_layer1)\n",
    "    if use_leakyRelu:cnn_layer2=tf.keras.layers.LeakyReLU()(cnn_layer2)\n",
    "\n",
    "    max_pool=tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(cnn_layer2)\n",
    "    dropout=tf.keras.layers.Dropout(dropout_rate)(max_pool)\n",
    "    flat=tf.keras.layers.Flatten()(dropout)\n",
    "    \n",
    "    dense1=tf.keras.layers.Dense(128, activation=activation)(flat)\n",
    "\n",
    "    dropout_output=tf.keras.layers.Dropout(dropout_rate)(dense1)\n",
    "    output_no_a=tf.keras.layers.Dense(10)(dropout_output)\n",
    "    output=tf.keras.layers.Activation('softmax')(output_no_a)\n",
    "    model=tf.keras.models.Model([cnn_input],[output])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'],label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Testing Loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "\n",
    "A great diagram I took from the link below.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*f8YjtxaYPid1Ilkw0tImaw.png\">\n",
    "<a href=https://medium.com/@ahmdtaha/dropout-as-a-bayesian-approximation-representing-model-uncertainty-in-deep-learning-7a2e49e64a15> Link to Article </a>\n",
    "\n",
    "\n",
    "Dropout randomly removes X% (where x is a hyperparameter) of the data from the previous layer, which makes memorizing the data much more difficult. This encourages the model to learn meaningful and independent features.\n",
    "\n",
    "Lets look what happens when we train different models, with only a small fraction training dataset (500 images)\n",
    "\n",
    "\n",
    "### Dropout 0% (no dropout)\n",
    "<img src=\"../assets/dropout_0.png\"  >\n",
    "This model quickly overfits\n",
    "\n",
    "### Dropout 50%\n",
    "<img src=\"../assets/dropout_0_50.png\" >\n",
    "This model does a bit better but over time still overfits\n",
    "\n",
    "\n",
    "### Dropout 70%\n",
    "<img src=\"../assets/dropout_0_70.png\"  >\n",
    "This model overfits even slower\n",
    "\n",
    "\n",
    "### Dropout 90%\n",
    "<img src=\"../assets/dropout_0_90.png\" >\n",
    "This model does not overfit, but takes much longer to train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(Y_train.shape)\n",
    "train_data=np.random.choice(range(0,len(X_train))  ,500 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Some code to produce the plots above\n",
    "if False:\n",
    "    for rate in [0,0.5,0.7,0.9]:\n",
    "        new_model=build_model(dropout_rate=rate)\n",
    "        print('Dropout Rate ',rate)\n",
    "        history=new_model.fit(X_train, Y_train_one_hot[train_data], \n",
    "              batch_size=32, epochs=200, verbose=0,\n",
    "             validation_data=(X_develop,Y_develop_one_hot) )     \n",
    "        score = new_model.evaluate(X_develop, Y_develop_one_hot)\n",
    "        print(\"Develop loss: {}, Develop accuracy: {}\".format(*score))\n",
    "\n",
    "        score = new_model.evaluate(X_train, Y_train_one_hot[train_data])\n",
    "        print(\"Train loss: {}, Train accuracy: {}\".format(*score))\n",
    "\n",
    "\n",
    "        plot_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activations\n",
    "\n",
    "Activations vary mainly on the output layer of a network\n",
    "* Binary Classification: Sigmoid\n",
    "* Multi-Class Classification: SoftMax\n",
    "* Regression: Linear\n",
    "\n",
    "\n",
    "However, activations can have a large impact on training. \n",
    "* I normally use a LeaklyReLU as my default choice\n",
    "  * Has non zero derivatives at +/- infinity\n",
    "\n",
    "See how some of the activation change below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=np.expand_dims(np.linspace(-10,10,50),1)\n",
    "\n",
    "act_input=tf.keras.Input((1,)) #Notice the comma after 1, this is a 1 dimentional input to keras\n",
    "output=tf.keras.layers.LeakyReLU()(act_input) #This is an \"Advanced Activation, so it has it's own layer\"\n",
    "\n",
    "\n",
    "sess=tf.keras.backend.get_session()\n",
    "output=sess.run(output,feed_dict={act_input:x})\n",
    "plt.plot(x,output)\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.title('LeakyReLU')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,15))    \n",
    "for i,activation in enumerate(['elu','selu','relu','softplus','softsign','tanh','sigmoid','hard_sigmoid','linear']):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    output=tf.keras.layers.Activation(activation)(act_input) \n",
    "    sess=tf.keras.backend.get_session()\n",
    "    output=sess.run(output,feed_dict={act_input:x})\n",
    "    plt.plot(x,output)\n",
    "    plt.xlabel('Input')\n",
    "    plt.ylabel('Output')\n",
    "    plt.title(activation)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model=build_model(dropout_rate=0.50,nfilters=32,activation='sigmoid')\n",
    "history=model.fit(X_train, Y_train_one_hot, \n",
    "      batch_size=32, epochs=10,\n",
    "     validation_data=(X_develop,Y_develop_one_hot) )   \n",
    "score = model.evaluate(X_develop, Y_develop_one_hot)\n",
    "print(\"Develop loss: {}, Develop accuracy: {}\".format(*score))\n",
    "\n",
    "score = model.evaluate(X_train, Y_train_one_hot)\n",
    "print(\"Train loss: {}, Train accuracy: {}\".format(*score))\n",
    "check(model,X_develop,Y_develop)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=build_model(dropout_rate=0.50,nfilters=32,use_leakyRelu=True)\n",
    "history=model.fit(X_train, Y_train_one_hot, \n",
    "      batch_size=32, epochs=10,\n",
    "     validation_data=(X_test,Y_test_one_hot) )    \n",
    "score = model.evaluate(X_test, Y_test_one_hot)\n",
    "print(\"Test loss: {}, Test accuracy: {}\".format(*score))\n",
    "\n",
    "score = model.evaluate(X_train, Y_train_one_hot)\n",
    "print(\"Train loss: {}, Train accuracy: {}\".format(*score))\n",
    "check(model,X_develop,Y_develop)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give it a Try on the cifar dataset\n",
    "* Try some of the options above to get the best accuracy you can with cifar?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check(model,X_develop,Y_develop)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
