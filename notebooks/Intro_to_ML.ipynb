{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning in Python\n",
    "\n",
    "Learn how to get started training Neural Networks with keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Mauritius_Road_Signs_-_Warning_Sign_-_Other_dangers.svg/556px-Mauritius_Road_Signs_-_Warning_Sign_-_Other_dangers.svg.png\" style=\"width:50px\">\n",
    "\n",
    "It's actually pretty easy to get started training Machine learning algorithms, but be aware there are plenty of examples of well trained, well coded, and well intentioned ML algorithms that do harmful things.\n",
    "\n",
    "\n",
    "<a href=\"https://www.technologyreview.com/s/613274/facebook-algorithm-discriminates-ai-bias\"> Facebook’s ad-serving algorithm discriminates by gender and race\n",
    " </a>\n",
    "    \n",
    "<a href=\"https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G\"> Amazon scraps secret AI recruiting tool that showed bias against women\n",
    " </a>\n",
    "\n",
    "<a href=\"https://www.thedailybeast.com/why-doctors-arent-afraid-of-better-more-efficient-ai-diagnosing-cancer\"> Ruler in picture an indicator for Cancer </a>\n",
    "\n",
    "<a href=\"https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist\"> Twitter taught Microsoft’s AI chatbot to be a racist asshole in less than a day </a>\n",
    "\n",
    "Be aware and careful before you deploy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.ap-south-1.amazonaws.com/techleer/207.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab\n",
    "## Artificial Intelligence\n",
    "An all encompassing term for a broad field the most promising of which is currently machine learning\n",
    "    \n",
    "## Machine Learning\n",
    "* Deep Learning - Deep Neural Networks of all forms\n",
    "* ‘Traditional’ Machine Learning  - Pretty much everything else\n",
    "    Trees, SVMs, Linear Regression, Naive Bayes...\n",
    "* **X’s = Input variables**\n",
    "* **Y’s = Target Variables**\n",
    "* Loss function - Numerical Goal of the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "* Find f(x) such that f(x) best approximates y\n",
    "* Examples:\n",
    "    * Given some pixels (x) tell me the probability it’s a cat (y)\n",
    "    * Given news articles (x) tell me a stocks value (y)\n",
    "    * Given some sequences x find some low dimensional space (z) that represent my data \n",
    "      * f1(x)=z f2(z)=x  \n",
    "* **Important Note: No prediction of causality** \n",
    "* Function outputs and targets can be stochastic \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "* Dense (Fully Connected Neural Networks)\n",
    "  * Example Fits\n",
    "* Sequences and Recurrent Neural Networks\n",
    "  * Learning to Count\n",
    "* Sentiment Analysis on movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning algorithms all start form a series data examples\n",
    "\n",
    "\n",
    "# Input Data\n",
    "* **numpy arrays** \n",
    "* pandas dataframes\n",
    "* hdf5, etc\n",
    "* **shape = (examples x data dimentions)** \n",
    "    * RGB Image Dataset (Number of images x Height x Width x 3) *(3=RGB)\n",
    "    * Text (Text blocks x ? ) examples with varying length can have an unspecified dimension size\n",
    "        * When training each batch needs to be the same length\n",
    "* Divide into 2 or 3 splits\n",
    "  * 2 Training/Testing (one for training and one for checking for over-fitting)\n",
    "  * 3 Training/Development/Testing \n",
    "      * One for training, one for checking for over-fitting (Development) )\n",
    "      * One for testing performance, but not for making any modeling decisions\n",
    "          * i.e. in this case testing is the data you want the model to actually work with  \n",
    "          \n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first Layer\n",
    "A Dense or fully connected layer\n",
    "\n",
    "<img src=\"../assets/dense.png\">\n",
    "\n",
    "A dense layer has a connection between every input variable and every output node. Each connection is represented by a weight $W_{i,n}$ from and input $X_n$ to an output $O_i$. The output is a sum over all the input variables times there weights plus a bias $B_i$\n",
    "<p style=\"text-align: center;\">\n",
    "$O_i = \\sum_n W_{i,n}*X_n+B_i$    \n",
    "</p>\n",
    "\n",
    "We will need to fit this to data, which means finding the best values for $W_{i,n}$ and $B_i$ to approximate our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start with a simple prediction a straight Line\n",
    "data_dim=5\n",
    "\n",
    "X=np.random.uniform(0,10,size=(10000,data_dim))\n",
    "def func(X):\n",
    "    return 2*X[:,0]+1 #Ignore all other input have the output only depend on the first dimention\n",
    "Y=func(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 3s 561us/step - loss: 63.4659 - val_loss: 41.2641\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 1s 165us/step - loss: 30.5968 - val_loss: 22.5257\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 1s 168us/step - loss: 19.4594 - val_loss: 16.8122\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 15.9096 - val_loss: 14.5414\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 1s 168us/step - loss: 13.9296 - val_loss: 12.7540\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 1s 160us/step - loss: 12.1540 - val_loss: 11.0477\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 10.4548 - val_loss: 9.4267\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 1s 174us/step - loss: 8.8592 - val_loss: 7.9268\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 7.3932 - val_loss: 6.5555\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 6.0724 - val_loss: 5.3404\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 4.9078 - val_loss: 4.2779\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 1s 171us/step - loss: 3.9030 - val_loss: 3.3713\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 1s 173us/step - loss: 3.0545 - val_loss: 2.6129\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 1s 161us/step - loss: 2.3455 - val_loss: 1.9880\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 1.7681 - val_loss: 1.4817\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 1.3057 - val_loss: 1.0816\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 0.9444 - val_loss: 0.7743\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 0.6686 - val_loss: 0.5425\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 1s 171us/step - loss: 0.4628 - val_loss: 0.3704\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 1s 165us/step - loss: 0.3125 - val_loss: 0.2470\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 0.2057 - val_loss: 0.1608\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 0.1329 - val_loss: 0.1032\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 1s 171us/step - loss: 0.0843 - val_loss: 0.0651\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 1s 162us/step - loss: 0.0534 - val_loss: 0.0413\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 1s 161us/step - loss: 0.0341 - val_loss: 0.0270\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 1s 167us/step - loss: 0.0227 - val_loss: 0.0187\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 0.0161 - val_loss: 0.0139\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 1s 166us/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 1s 173us/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 1s 174us/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 1s 174us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 1s 174us/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 1s 159us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 1s 160us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 1s 174us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 1s 176us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 1s 176us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 1s 171us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 1s 166us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 1s 176us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 1s 174us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 1s 175us/step - loss: 0.0011 - val_loss: 9.7312e-04\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 1s 175us/step - loss: 8.6141e-04 - val_loss: 7.7864e-04\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 1s 171us/step - loss: 6.7679e-04 - val_loss: 6.0213e-04\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 5.2124e-04 - val_loss: 4.5893e-04\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 3.9436e-04 - val_loss: 3.4053e-04\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 2.9029e-04 - val_loss: 2.4855e-04\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 1s 171us/step - loss: 2.1004e-04 - val_loss: 1.7708e-04\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 1s 175us/step - loss: 1.4541e-04 - val_loss: 1.2183e-04\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 1s 173us/step - loss: 9.9124e-05 - val_loss: 8.1361e-05\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 1s 174us/step - loss: 6.5215e-05 - val_loss: 5.1941e-05\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 1s 175us/step - loss: 4.1208e-05 - val_loss: 3.2469e-05\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 2.5530e-05 - val_loss: 1.9681e-05\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 1.4992e-05 - val_loss: 1.2011e-05\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 1s 174us/step - loss: 8.4593e-06 - val_loss: 6.1776e-06\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 1s 174us/step - loss: 4.5227e-06 - val_loss: 3.1998e-06\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 2.3334e-06 - val_loss: 1.6711e-06\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 1s 176us/step - loss: 1.1142e-06 - val_loss: 7.4216e-07\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 1s 175us/step - loss: 5.1228e-07 - val_loss: 3.2164e-07\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 1s 166us/step - loss: 2.1434e-07 - val_loss: 1.3031e-07\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 1s 168us/step - loss: 8.4357e-08 - val_loss: 4.9791e-08\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 1s 171us/step - loss: 3.0849e-08 - val_loss: 1.7357e-08\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 1s 176us/step - loss: 1.0437e-08 - val_loss: 5.9523e-09\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 1s 173us/step - loss: 3.1589e-09 - val_loss: 1.5909e-09\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 1s 168us/step - loss: 8.9647e-10 - val_loss: 4.2420e-10\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 2.3915e-10 - val_loss: 1.1191e-10\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 1s 173us/step - loss: 6.4259e-11 - val_loss: 3.5672e-11\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 2.4339e-11 - val_loss: 1.3898e-11\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 1.2666e-11 - val_loss: 1.2283e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 1s 173us/step - loss: 1.0535e-11 - val_loss: 7.6694e-12\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 1s 165us/step - loss: 7.5813e-12 - val_loss: 6.7169e-12\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 1s 161us/step - loss: 6.4616e-12 - val_loss: 6.2074e-12\n",
      "Epoch 79/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 6.8350e-12 - val_loss: 5.9069e-12\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 1s 167us/step - loss: 5.1715e-12 - val_loss: 4.9490e-12\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 4.6298e-12 - val_loss: 4.8386e-12\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 1s 163us/step - loss: 3.4486e-12 - val_loss: 1.8550e-12\n",
      "Epoch 83/100\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 1.2456e-12 - val_loss: 1.2269e-12\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 1s 164us/step - loss: 2.1513e-12 - val_loss: 1.5408e-12\n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 1.9608e-12 - val_loss: 1.9469e-12\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 1s 173us/step - loss: 1.9797e-12 - val_loss: 2.3867e-12\n",
      "Epoch 87/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 1.3774e-12 - val_loss: 4.0699e-13\n",
      "Epoch 88/100\n",
      "5000/5000 [==============================] - 1s 173us/step - loss: 4.7028e-13 - val_loss: 4.6546e-13\n",
      "Epoch 89/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 4.5879e-13 - val_loss: 4.1301e-13\n",
      "Epoch 90/100\n",
      "5000/5000 [==============================] - 1s 170us/step - loss: 4.8390e-13 - val_loss: 3.5888e-13\n",
      "Epoch 91/100\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 4.7718e-13 - val_loss: 9.2117e-13\n",
      "Epoch 92/100\n",
      "5000/5000 [==============================] - 1s 173us/step - loss: 5.1558e-13 - val_loss: 4.7721e-13\n",
      "Epoch 93/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 5.3460e-13 - val_loss: 5.4499e-13\n",
      "Epoch 94/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 5.6076e-13 - val_loss: 6.6051e-13\n",
      "Epoch 95/100\n",
      "5000/5000 [==============================] - 1s 162us/step - loss: 4.3695e-13 - val_loss: 6.0226e-14\n",
      "Epoch 96/100\n",
      "5000/5000 [==============================] - 1s 171us/step - loss: 1.0268e-13 - val_loss: 7.1236e-14\n",
      "Epoch 97/100\n",
      "5000/5000 [==============================] - 1s 173us/step - loss: 1.0045e-13 - val_loss: 6.7101e-14\n",
      "Epoch 98/100\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 8.2741e-14 - val_loss: 6.7956e-14\n",
      "Epoch 99/100\n",
      "5000/5000 [==============================] - 1s 169us/step - loss: 9.4988e-14 - val_loss: 6.9107e-14\n",
      "Epoch 100/100\n",
      "5000/5000 [==============================] - 1s 172us/step - loss: 1.0168e-13 - val_loss: 7.1998e-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd455ae2e48>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All models start out with an input layer\n",
    "\n",
    "input_layer=tf.keras.layers.Input(shape=(data_dim,)) \n",
    "output_layer = tf.keras.layers.Dense(1)(input_layer)\n",
    "#A keras model is class used for fitting it takes input layers and output layers\n",
    "model=tf.keras.models.Model(input_layer,output_layer)\n",
    "\n",
    "#MSE= Mean Squared Error \n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "# Fit Our Simple Neural Network\n",
    "# Stop fitting when the validation loss stops improving\n",
    "es=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "#Fit\n",
    "model.fit(X,Y,epochs=100,validation_split=0.5,callbacks=[es]) #Have Keras make a test/validation split for us\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd453d1e518>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test=np.random.uniform(0,10,size=(100,data_dim))\n",
    "X_test[:,0]=np.linspace(-5,15,100)\n",
    "Y_test=func(X_test)\n",
    "Y_pred=model.predict(X_test)\n",
    "\n",
    "plt.scatter(X_test[:,0],Y_pred,label='prediction')\n",
    "plt.scatter(X_test[:,0],Y_test,label='truth')\n",
    "plt.xlabel('X[:,0]')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at a models weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(5, 1) (1,)\n",
      "[[ 2.0000000e+00]\n",
      " [ 1.2722031e-08]\n",
      " [ 2.5370291e-08]\n",
      " [-5.1710254e-09]\n",
      " [ 2.6714067e-08]]\n"
     ]
    }
   ],
   "source": [
    "weights=model.get_weights()\n",
    "print(len(weights))\n",
    "print(weights[0].shape,weights[1].shape)\n",
    "\n",
    "print(weights[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect $W_{0,0}$=2, and $B_0$=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W= [[ 2.0000000e+00]\n",
      " [ 1.2722031e-08]\n",
      " [ 2.5370291e-08]\n",
      " [-5.1710254e-09]\n",
      " [ 2.6714067e-08]]\n",
      "W[0,0]= 2.0\n",
      "B= [0.9999999]\n"
     ]
    }
   ],
   "source": [
    "print(\"W=\",weights[0])\n",
    "print(\"W[0,0]=\",weights[0][0,0])\n",
    "print(\"B=\",weights[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try something a bit more complicated a sin wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 1s 177us/step - loss: 50.3590 - val_loss: 30.9382\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 1s 131us/step - loss: 20.4459 - val_loss: 14.3333\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 11.2296 - val_loss: 9.7768\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 1s 124us/step - loss: 8.6132 - val_loss: 8.0730\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 1s 130us/step - loss: 7.2525 - val_loss: 6.8131\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 1s 131us/step - loss: 6.0812 - val_loss: 5.6644\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 1s 125us/step - loss: 5.0062 - val_loss: 4.6146\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 4.0528 - val_loss: 3.6992\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 3.2301 - val_loss: 2.9274\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 2.5394 - val_loss: 2.2894\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 1.9805 - val_loss: 1.7777\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 1.5391 - val_loss: 1.3814\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 1s 126us/step - loss: 1.2012 - val_loss: 1.0838\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 0.9504 - val_loss: 0.8659\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 1s 130us/step - loss: 0.7711 - val_loss: 0.7142\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 1s 131us/step - loss: 0.6467 - val_loss: 0.6104\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 1s 128us/step - loss: 0.5642 - val_loss: 0.5418\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 1s 127us/step - loss: 0.5112 - val_loss: 0.5003\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 0.4792 - val_loss: 0.4762\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 0.4600 - val_loss: 0.4613\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 1s 128us/step - loss: 0.4494 - val_loss: 0.4528\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 1s 128us/step - loss: 0.4438 - val_loss: 0.4501\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 1s 128us/step - loss: 0.4408 - val_loss: 0.4469\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 1s 126us/step - loss: 0.4390 - val_loss: 0.4484\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 1s 130us/step - loss: 0.4383 - val_loss: 0.4464\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 0.4386 - val_loss: 0.4455\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 1s 127us/step - loss: 0.4381 - val_loss: 0.4456\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 1s 125us/step - loss: 0.4386 - val_loss: 0.4459\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 1s 130us/step - loss: 0.4381 - val_loss: 0.4458\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 1s 130us/step - loss: 0.4384 - val_loss: 0.4462\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 1s 130us/step - loss: 0.4379 - val_loss: 0.4497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdc6c552898>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X=np.random.uniform(0,10,size=(10000,data_dim))\n",
    "def func(X):\n",
    "    return np.sin(X[:,0]) #Ignore all other input have the output only depend on the first dimention\n",
    "Y=func(X)\n",
    "\n",
    "# All models start out with an input layer\n",
    "\n",
    "input_layer=tf.keras.layers.Input(shape=(data_dim,)) \n",
    "output_layer = tf.keras.layers.Dense(1)(input_layer)\n",
    "#A keras model is a way of going from one layer to the next\n",
    "model=tf.keras.models.Model(input_layer,output_layer)\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit(X,Y,epochs=100,validation_split=0.5,callbacks=[es]) #Have Keras make a test/validation split for us\n",
    "\n",
    "\n",
    "X_test=np.random.uniform(0,10,size=(100,data_dim))\n",
    "X_test[:,0]=np.linspace(-5,15,100)\n",
    "Y_test=func(X_test)\n",
    "Y_pred=model.predict(X_test)\n",
    "\n",
    "plt.scatter(X_test[:,0],Y_pred,label='prediction')\n",
    "plt.scatter(X_test[:,0],Y_test,label='truth')\n",
    "plt.xlabel('X[:,0]')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops this didn't work. So far what we wrote above can only be linear\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "$O_i = \\sum_n W_{i,n}*X_n+B_i$    \n",
    "</p>\n",
    "\n",
    "we need to add something called an activation function $\\sigma$\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "$O_i = \\sigma(\\sum_n W_{i,n}*X_n+B_i)$    \n",
    "</p>\n",
    "\n",
    "$\\sigma$ has to be non-linear and a good choice is a LeakyReLU\n",
    "\n",
    "<img src='../assets/leakyReLU.png'>\n",
    "\n",
    "Let's also make our model a bit more powerful, but adding more layers $l$\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "$O_i,o=X_i$\n",
    "</p>\n",
    " \n",
    "<p style=\"text-align: center;\">  \n",
    "$O_{i,l} = \\sigma(\\sum_n W_{i,l,n}*O_{i,l-1}+B_{i,l})$    \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 20)                120       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 981\n",
      "Trainable params: 981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 3s 676us/step - loss: 0.5868 - val_loss: 0.4200\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 1s 268us/step - loss: 0.3830 - val_loss: 0.3852\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 1s 271us/step - loss: 0.3518 - val_loss: 0.3388\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 1s 267us/step - loss: 0.3339 - val_loss: 0.3257\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 1s 261us/step - loss: 0.3172 - val_loss: 0.3246\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 1s 270us/step - loss: 0.3041 - val_loss: 0.2933\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 1s 261us/step - loss: 0.2897 - val_loss: 0.2840\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 1s 268us/step - loss: 0.2768 - val_loss: 0.2632\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 1s 264us/step - loss: 0.2601 - val_loss: 0.2544\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 1s 258us/step - loss: 0.2360 - val_loss: 0.2362\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 1s 260us/step - loss: 0.2133 - val_loss: 0.2194\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 1s 269us/step - loss: 0.1941 - val_loss: 0.1893\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 1s 268us/step - loss: 0.1759 - val_loss: 0.1728\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 1s 266us/step - loss: 0.1658 - val_loss: 0.1708\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 1s 260us/step - loss: 0.1499 - val_loss: 0.1460\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 1s 261us/step - loss: 0.1427 - val_loss: 0.1350\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 1s 252us/step - loss: 0.1364 - val_loss: 0.1285\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 1s 264us/step - loss: 0.1294 - val_loss: 0.1201\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 1s 268us/step - loss: 0.1189 - val_loss: 0.1182\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 1s 267us/step - loss: 0.1146 - val_loss: 0.1072\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 1s 260us/step - loss: 0.1093 - val_loss: 0.1033\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 1s 262us/step - loss: 0.1005 - val_loss: 0.0984\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 1s 267us/step - loss: 0.0953 - val_loss: 0.0952\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 1s 270us/step - loss: 0.0899 - val_loss: 0.0875\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 1s 267us/step - loss: 0.0829 - val_loss: 0.0772\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 1s 271us/step - loss: 0.0765 - val_loss: 0.0686\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 1s 264us/step - loss: 0.0657 - val_loss: 0.0645\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 1s 268us/step - loss: 0.0579 - val_loss: 0.0556\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 1s 269us/step - loss: 0.0500 - val_loss: 0.0434\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 1s 264us/step - loss: 0.0473 - val_loss: 0.0369\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 1s 266us/step - loss: 0.0355 - val_loss: 0.0312\n",
      "Epoch 32/50\n",
      "5000/5000 [==============================] - 1s 260us/step - loss: 0.0294 - val_loss: 0.0262\n",
      "Epoch 33/50\n",
      "5000/5000 [==============================] - 1s 267us/step - loss: 0.0238 - val_loss: 0.0194\n",
      "Epoch 34/50\n",
      "5000/5000 [==============================] - 1s 268us/step - loss: 0.0204 - val_loss: 0.0164\n",
      "Epoch 35/50\n",
      "5000/5000 [==============================] - 1s 263us/step - loss: 0.0149 - val_loss: 0.0144\n",
      "Epoch 36/50\n",
      "5000/5000 [==============================] - 1s 263us/step - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 37/50\n",
      "5000/5000 [==============================] - 1s 265us/step - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 38/50\n",
      "5000/5000 [==============================] - 1s 269us/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 39/50\n",
      "5000/5000 [==============================] - 1s 269us/step - loss: 0.0079 - val_loss: 0.0101\n",
      "Epoch 40/50\n",
      "5000/5000 [==============================] - 1s 263us/step - loss: 0.0070 - val_loss: 0.0084\n",
      "Epoch 41/50\n",
      "5000/5000 [==============================] - 1s 269us/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 42/50\n",
      "5000/5000 [==============================] - 1s 267us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 43/50\n",
      "5000/5000 [==============================] - 1s 267us/step - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 44/50\n",
      "5000/5000 [==============================] - 1s 261us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 45/50\n",
      "5000/5000 [==============================] - 1s 266us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 46/50\n",
      "5000/5000 [==============================] - 1s 268us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 47/50\n",
      "5000/5000 [==============================] - 1s 266us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 48/50\n",
      "5000/5000 [==============================] - 1s 267us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 49/50\n",
      "5000/5000 [==============================] - 1s 268us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 50/50\n",
      "5000/5000 [==============================] - 1s 265us/step - loss: 0.0026 - val_loss: 0.0026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd453607a20>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X=np.random.uniform(0,10,size=(10000,data_dim))\n",
    "def func(X):\n",
    "    return np.sin(X[:,0]) #Ignore all other input have the output only depend on the first dimention\n",
    "Y=func(X)\n",
    "\n",
    "# All models start out with an input layer\n",
    "\n",
    "input_layer=tf.keras.layers.Input(shape=(data_dim,)) \n",
    "###Lets Add another layer and an Activation###\n",
    "nn = tf.keras.layers.Dense(20)(input_layer)\n",
    "nn = tf.keras.layers.LeakyReLU()(nn)\n",
    "\n",
    "nn = tf.keras.layers.Dense(20)(nn)\n",
    "nn = tf.keras.layers.LeakyReLU()(nn)\n",
    "\n",
    "nn = tf.keras.layers.Dense(20)(nn)\n",
    "nn = tf.keras.layers.LeakyReLU()(nn)\n",
    "\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(1)(nn)\n",
    "#A keras model is a way of going from one layer to the next\n",
    "model=tf.keras.models.Model(input_layer,output_layer)\n",
    "model.summary()\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit(X,Y,epochs=50,validation_split=0.5,callbacks=[es]) #Have Keras make a test/validation split for us\n",
    "\n",
    "\n",
    "X_test=np.random.uniform(0,10,size=(100,data_dim))\n",
    "X_test[:,0]=np.linspace(-5,15,100)\n",
    "Y_test=func(X_test)\n",
    "Y_pred=model.predict(X_test)\n",
    "\n",
    "plt.scatter(X_test[:,0],Y_pred,label='prediction')\n",
    "plt.scatter(X_test[:,0],Y_test,label='truth')\n",
    "plt.xlabel('X[:,0]')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data fits the sin curve perfectly where it had seen training data 0-10, and not so well where there was no training data. Neural networks are universal function approximators, you have little control of what they predict when given data that is completely new. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense network summary\n",
    "\n",
    "* Dense networks take fixed length input and have a fixed length output\n",
    "* Like All Neural Network layers they require an activation function\n",
    "* They can be stacked to represent more complicated functions\n",
    "* You're taking your chances when predicting data that's very different from you're training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences\n",
    "A lot of data we have doesn't have a fixed dimension, for example text. To make our predictions we need another kind of layer called a recurrent layer. \n",
    "\n",
    "<img src=\"../assets/rnn.gif\">\n",
    "\n",
    "Recurrent layers step through each data point in a sequence, and output one number at the end (or another sequence)\n",
    "Examples:\n",
    "* RNN : First simplest recurrent layer\n",
    "* LSTM: Long Short Term Memory Networks\n",
    "* GRU: Gated Recurrent Unit\n",
    "\n",
    "All of the above are implemented differently with different strengths, but for now lets stick with an LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_39:0\", shape=(?, ?, 1), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        (None, None, 1)           0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 1081.0467 - val_loss: 1071.3975\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 4s 720us/step - loss: 1080.4070 - val_loss: 1069.1196\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 4s 719us/step - loss: 1070.3395 - val_loss: 1036.5711\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 4s 716us/step - loss: 592.1027 - val_loss: 4.5454\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 4s 711us/step - loss: 3.4930 - val_loss: 2.6813\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 4s 726us/step - loss: 2.3137 - val_loss: 1.8856\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 4s 712us/step - loss: 1.4789 - val_loss: 1.1646\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 3s 695us/step - loss: 0.9479 - val_loss: 0.8005\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 4s 709us/step - loss: 0.7691 - val_loss: 0.7346\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 4s 723us/step - loss: 0.7021 - val_loss: 0.6587\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 4s 706us/step - loss: 0.6930 - val_loss: 0.6941\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 4s 712us/step - loss: 0.6528 - val_loss: 0.6717\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 4s 727us/step - loss: 0.7025 - val_loss: 0.5779\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 4s 731us/step - loss: 0.6184 - val_loss: 0.7458\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 4s 734us/step - loss: 0.6233 - val_loss: 0.5544\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 4s 718us/step - loss: 0.5887 - val_loss: 0.5494\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 4s 716us/step - loss: 0.5441 - val_loss: 0.4954\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 4s 723us/step - loss: 0.5407 - val_loss: 0.4921\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 4s 723us/step - loss: 0.5211 - val_loss: 0.4608\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 4s 733us/step - loss: 0.4991 - val_loss: 0.5696\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 4s 725us/step - loss: 0.4758 - val_loss: 0.4200\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 4s 728us/step - loss: 0.4867 - val_loss: 0.4896\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 4s 718us/step - loss: 0.4666 - val_loss: 0.3826\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 4s 711us/step - loss: 0.3642 - val_loss: 0.3519\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 4s 720us/step - loss: 0.2952 - val_loss: 0.2481\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 4s 705us/step - loss: 0.2405 - val_loss: 0.2097\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 4s 717us/step - loss: 0.2017 - val_loss: 0.1777\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 4s 722us/step - loss: 0.1666 - val_loss: 0.1661\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 4s 712us/step - loss: 0.1463 - val_loss: 0.1197\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 4s 730us/step - loss: 0.1185 - val_loss: 0.0990\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 4s 730us/step - loss: 0.0917 - val_loss: 0.0831\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 4s 729us/step - loss: 0.0664 - val_loss: 0.0468\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 4s 729us/step - loss: 0.0435 - val_loss: 0.0335\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 4s 727us/step - loss: 0.0385 - val_loss: 0.0284\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 4s 712us/step - loss: 0.0310 - val_loss: 0.0296\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 4s 721us/step - loss: 0.0288 - val_loss: 0.0308\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 4s 731us/step - loss: 0.0334 - val_loss: 0.0231\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 4s 715us/step - loss: 0.0301 - val_loss: 0.0228\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 4s 728us/step - loss: 0.0248 - val_loss: 0.0632\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 4s 712us/step - loss: 0.0247 - val_loss: 0.0203\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 4s 730us/step - loss: 0.0239 - val_loss: 0.0190\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 4s 728us/step - loss: 0.0249 - val_loss: 0.0246\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 4s 730us/step - loss: 0.0226 - val_loss: 0.0546\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 4s 715us/step - loss: 0.0314 - val_loss: 0.0200\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 4s 726us/step - loss: 0.0338 - val_loss: 0.0277\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 4s 727us/step - loss: 0.0244 - val_loss: 0.0178\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 4s 728us/step - loss: 0.0212 - val_loss: 0.0579\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 4s 743us/step - loss: 0.0575 - val_loss: 0.0295\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 4s 732us/step - loss: 0.0227 - val_loss: 0.0178\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 4s 721us/step - loss: 0.0184 - val_loss: 0.0170\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 4s 728us/step - loss: 0.0153 - val_loss: 0.0141\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 4s 726us/step - loss: 0.0168 - val_loss: 0.0145\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 4s 711us/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 4s 727us/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 4s 721us/step - loss: 0.0168 - val_loss: 0.0154\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 4s 721us/step - loss: 0.0107 - val_loss: 0.0206\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 4s 718us/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 4s 721us/step - loss: 0.0162 - val_loss: 0.0127\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 4s 726us/step - loss: 0.0144 - val_loss: 0.0315\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 4s 716us/step - loss: 0.0121 - val_loss: 0.0801\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 4s 727us/step - loss: 0.1039 - val_loss: 0.0093\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 4s 716us/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 4s 719us/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 4s 722us/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 4s 728us/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 4s 727us/step - loss: 0.0088 - val_loss: 0.0093\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 4s 724us/step - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 4s 721us/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 4s 718us/step - loss: 0.0076 - val_loss: 0.0185\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 4s 726us/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 4s 727us/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 4s 715us/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 4s 711us/step - loss: 0.0079 - val_loss: 0.0110\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 4s 703us/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 4s 729us/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 4s 719us/step - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 4s 719us/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 4s 715us/step - loss: 0.0067 - val_loss: 0.0133\n",
      "Epoch 79/100\n",
      "5000/5000 [==============================] - 4s 720us/step - loss: 0.0077 - val_loss: 0.0150\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 4s 724us/step - loss: 0.0235 - val_loss: 0.0043\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 4s 727us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 4s 715us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 83/100\n",
      "5000/5000 [==============================] - 4s 722us/step - loss: 0.0050 - val_loss: 0.0209\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 4s 725us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 4s 723us/step - loss: 0.0038 - val_loss: 0.0064\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 4s 726us/step - loss: 0.0054 - val_loss: 0.0054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd454c851d0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer=tf.keras.layers.Input((None,1))\n",
    "print(input_layer)\n",
    "output_layer=tf.keras.layers.LSTM(1,activation='linear')(input_layer)\n",
    "model=tf.keras.models.Model([input_layer],[output_layer])\n",
    "opt=tf.keras.optimizers.Adam(lr=1e-3)\n",
    "\n",
    "model.compile(loss='mse',optimizer=opt)\n",
    "model.summary()\n",
    "es=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "model.fit(X,Y,validation_split=0.5,epochs=100,callbacks=[es])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.]\n",
      " [23.]\n",
      " [24.]\n",
      " [25.]\n",
      " [26.]] 27.0\n",
      "(10000, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "for i in range(10000):\n",
    "    _dp=[]\n",
    "    _dp=np.random.randint(50)+np.linspace(0,4,5)\n",
    "    Y.append(_dp[-1]+1)\n",
    "    X.append(np.expand_dims(_dp,-1))\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "print(X[0],Y[0])\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9389105]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims([[2,3,4,5,6]],-1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data\n",
    "\n",
    "The coding/research part of most machine learning algorithms is how to utilize data in a way an algorthim understands.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Read the raw the raw text from these movie reviews, and predict wether the review is positive or not\n",
    "* Need to go from an array (1-D unknown length) to a probability (1 number)\n",
    "* Need to build a series of layers to make that possible\n",
    "\n",
    "\n",
    "\n",
    "* We will take text that is transformed into an sequence of integers\n",
    "  * For this data we assign each word (token) in a sentence a unique integer\n",
    "    * include a token (integer) for unknown, pad, and start\n",
    "\n",
    "* We will transform the sequence of integers into an sequence of vectors\n",
    "    * Do this with a new Embedding Layer\n",
    "* Then use an LSTM layer, and a Dense layer to make a prediction\n",
    "\n",
    "\n",
    "Array of Ints -> **Embedding** -> Array of Vectors -> **RNN** -> fixed output -> **Dense** -> Probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load some input data in the 2-split format\n",
    "index_from=3\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(path=\"imdb.npz\",\n",
    "                                                      num_words=None,\n",
    "                                                      skip_top=0,\n",
    "                                                      maxlen=None,\n",
    "                                                      seed=113,\n",
    "                                                      start_char=1,\n",
    "                                                      oov_char=2,\n",
    "                                                      index_from=index_from)\n",
    "\n",
    "\n",
    "word_2_index={k:(v+index_from) for k,v in tf.keras.datasets.imdb.get_word_index().items()}\n",
    "word_2_index['<PAD>']=0\n",
    "word_2_index['<START>']=1\n",
    "word_2_index['<UNK>']=2\n",
    "\n",
    "index_2_word={}\n",
    "\n",
    "for word in word_2_index:\n",
    "    index_2_word[ word_2_index[word]]=word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'sentence'] [14, 9, 6, 4130]\n"
     ]
    }
   ],
   "source": [
    "check=['this','is','a','sentence']\n",
    "print(check, [word_2_index[i] for i in check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_word=np.max(list(word_2_index.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n",
      "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "1 = Positive Review 0 = Negative Review \n",
      "label 1\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "\n",
    "print(\" \".join([index_2_word[i] for i in x_train[0]]))\n",
    "\n",
    "print('1 = Positive Review','0 = Negative Review ')\n",
    "print('label',y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "This data has already been 'tokenized' meaning the text has been pre-processed. In this case made lowercase with punctuation removed. There are many different ways of doing this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_44:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_layer=tf.keras.layers.Input( (None,))\n",
    "print(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, None, 100)         8858700   \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 10)                4440      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 8,863,261\n",
      "Trainable params: 8,863,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn=tf.keras.layers.Embedding(last_word,100)(input_layer)\n",
    "nn=tf.keras.layers.LSTM(10)(nn)\n",
    "nn=tf.keras.layers.Dense(10)(nn)\n",
    "nn=tf.keras.layers.LeakyReLU()(nn)\n",
    "output=tf.keras.layers.Dense(1,activation='sigmoid')(nn)\n",
    "\n",
    "model=tf.keras.models.Model(input_layer,output)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy\n",
    "\n",
    "Our last layer here is using a sigmoid activation, which is bounded between zero and 1\n",
    "\n",
    "<img src=\"../assets/sigmoid.png\">\n",
    "\n",
    "The activation on your last layer has to match your loss function in this case 'Binary Cross-Entropy'\n",
    "<p style=\"text-align: center;\">\n",
    "$L= -1*\\sum_i y_{true,i}*ln(y_{pred,i}) + (1-y_{true,i})*ln(1-y_{pred,i}) $\n",
    "</p>\n",
    "Which is minimized when $y_{pred}=y_{true}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need each batch given to the model to have the same size\n",
    "# For right now we will just make all the data the same size by padding or cropping to a length of 200\n",
    "\n",
    "x_train=tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=200, dtype='int32',value=0.0)\n",
    "x_test=tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=200, dtype='int32',value=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 310s 12ms/step - loss: 0.3882 - acc: 0.8226 - val_loss: 0.3458 - val_acc: 0.8571\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 302s 12ms/step - loss: 0.1624 - acc: 0.9408 - val_loss: 0.3414 - val_acc: 0.8616\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 302s 12ms/step - loss: 0.0706 - acc: 0.9764 - val_loss: 0.4841 - val_acc: 0.8582\n"
     ]
    }
   ],
   "source": [
    "es=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=0, mode='auto')\n",
    "history=model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_2_ints(sentence):\n",
    "    return np.array([[word_2_index[s] for s in sentence.split()]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90006727]]\n",
      "[[0.79725325]]\n",
      "[[0.88183933]]\n",
      "[[0.05837091]]\n",
      "[[0.8210077]]\n",
      "[[0.26951432]]\n",
      "[[0.34072697]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(sentence_2_ints('<START> this movie is the very best i have ever seen') ))\n",
    "\n",
    "print(model.predict(sentence_2_ints('<START> i have mixed feelings about this movie') ))\n",
    "print(model.predict(sentence_2_ints('<START> i have mixed feelings about this movie i may like it in the end') ))\n",
    "\n",
    "print(model.predict(sentence_2_ints('<START> i have never seen a worse film') ))\n",
    "print(model.predict(sentence_2_ints('<START> hi is this where i google the information') ))\n",
    "\n",
    "print(model.predict(sentence_2_ints('<START> star trek') ))\n",
    "print(model.predict(sentence_2_ints('<START> star wars') ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A short Menu of other ML layers\n",
    "* Convolutional Layers (Conv1D, Conv2D, Conv3D)\n",
    "    * Input sequences of fixed or varying length best when array values that are close together are correlate i.e pictures\n",
    "    * Output a new sequence normally lower dimension, but with more channels    \n",
    "* Recurrent Neural Networks (RNN, LSTM, GRUS)\n",
    "    * Input sequence\n",
    "    * Output sequence or a fixed dimensional output    \n",
    "\n",
    "* Embedding Network\n",
    "    * A learnable mapping from a large set of integers, to a fixed output\n",
    "    * Input integer\n",
    "    * Ouput vector\n",
    "\n",
    "* Dense Network\n",
    "    * Fixed Input\n",
    "    * Fixed Output\n",
    "\n",
    "* Dropout\n",
    "    * Good at preventing overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
